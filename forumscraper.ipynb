{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f29d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec99981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetThreads():\n",
    "    def __init__(self, page_num, find_threads, find_authors, find_replies, find_views, find_titles):\n",
    "        self.page_num = page_num\n",
    "        self.find_threads = find_threads\n",
    "        self.find_authors = find_authors\n",
    "        self.find_replies = find_replies\n",
    "        self.find_views = find_views\n",
    "        self.find_titles = find_titles\n",
    "\n",
    "    def isolate_author(self):\n",
    "        authors = []\n",
    "        for i in range(len(self.find_authors)):\n",
    "            text = self.find_authors[i].getText()\n",
    "            author = text.split()[0][:-2]\n",
    "            authors.append(author)\n",
    "        return authors\n",
    "    \n",
    "    def isolate_views(self):\n",
    "        views = []\n",
    "        for i in range(len(self.find_views)):\n",
    "            total_views = int(self.find_views[i].getText().replace(\" \",'').replace(',','')[5:-4])\n",
    "            views.append(total_views)\n",
    "        return views\n",
    "    \n",
    "    def isolate_replies(self):\n",
    "        replies = []\n",
    "        for i in range(len(self.find_replies)):\n",
    "            total_replies = int(self.find_replies[i].getText().replace(\" \",'').replace(',','')[5:-4])\n",
    "            replies.append(total_replies)\n",
    "        return replies\n",
    "        \n",
    "    def isolate_titles_links(self):\n",
    "        titles = []\n",
    "        links = []\n",
    "        for i in range(len(self.find_titles)):\n",
    "            title = self.find_titles[i].find('a').getText()[34:-30]\n",
    "            ahref = self.find_titles[i].find('a', href=True)['href']\n",
    "            titles.append(title)\n",
    "            links.append(ahref)\n",
    "\n",
    "        return [titles, links]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38844402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeThreads():\n",
    "    threadsMap = {}\n",
    "    for num in range(1,339):\n",
    "        print(f'Page {num}')\n",
    "        url = f'https://forum.bodybuilding.com/forumdisplay.php?f=19&page={num}&order=desc'\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text,'html.parser')\n",
    "        find_threads = soup.find_all('div', {'class':\"threadinfo\"})\n",
    "        find_authors = soup.find_all('div', {'class':\"author\"})\n",
    "        find_replies = soup.find_all('td', {'class':\"othercol td-reply\"})\n",
    "        find_views = soup.find_all('td', {'class':\"alt-col othercol td-views\"})\n",
    "        find_titles = soup.find_all('h3', {'class':\"threadtitle\"})\n",
    "        misc = GetThreads(num, find_threads, find_authors, find_replies, find_views, find_titles)\n",
    "        authors = misc.isolate_author()\n",
    "        views = misc.isolate_views()\n",
    "        replies = misc.isolate_replies()\n",
    "        titles = misc.isolate_titles_links()[0]\n",
    "        links = misc.isolate_titles_links()[1]\n",
    "        for i in range(len(links)):\n",
    "            author = authors[i]\n",
    "            threadviews = views[i]\n",
    "            threadreplies = replies[i]\n",
    "            threadtitle = titles[i]\n",
    "            threadlink = links[i]\n",
    "            if threadlink in threadsMap:\n",
    "                continue\n",
    "            threadsMap[threadlink] = [threadtitle, author, threadviews, threadreplies]  \n",
    "\n",
    "    return threadsMap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ceb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threadsData = scrapeThreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "073131db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_replies = misc_df.sort_values(by=['Replies'], ascending=False).head(100)\n",
    "# by_views = misc_df.sort_values(by=['View'], ascending=False).head(100)\n",
    "# unique_miscers = misc_df['Author'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "f6eb156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #views = misc_df.loc[misc_df['Author'].unique(), 'View'].sum()\n",
    "\n",
    "# #f2 = misc_df.groupby(['Author'])['View'].count().to_frame()\n",
    "\n",
    "# f1 = misc_df['Author'].value_counts().to_frame()\n",
    "# f2 = misc_df.groupby('Author')['Replies'].sum().to_frame()\n",
    "# f3 = misc_df.groupby('Author')['View'].sum().to_frame()\n",
    "# f5 = f1.merge(f2, left_index=True, right_index=True).merge(f3, left_index=True, right_index=True)\n",
    "# f5.to_excel('topPosters.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051cac81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4eba99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
